{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd655203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189c57e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/data/andrewbai/Natural-Disaster-Image-Generation-to-raise-Environmental-Awareness/src\n",
      "/nfs/data/andrewbai/Natural-Disaster-Image-Generation-to-raise-Environmental-Awareness/guided-diffusion\n"
     ]
    }
   ],
   "source": [
    "paths = ['../src/', '../guided-diffusion/']\n",
    "for path in paths:\n",
    "    if os.path.abspath(path) not in sys.path:\n",
    "        sys.path.insert(0, os.path.abspath(path))\n",
    "        print(os.path.abspath(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b205689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d63f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import functools\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23f714a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glide_text2im.gaussian_diffusion import GaussianDiffusion\n",
    "from glide_text2im.model_creation import model_and_diffusion_defaults, create_model\n",
    "from glide_text2im.gaussian_diffusion import get_named_beta_schedule\n",
    "from glide_text2im.respace import space_timesteps\n",
    "from glide_text2im.nn import timestep_embedding, zero_module\n",
    "from glide_text2im.text2im_model import (\n",
    "    Text2ImUNet, \n",
    "    SuperResInpaintText2ImUnet,\n",
    "    InpaintText2ImUNet,\n",
    "    SuperResText2ImUNet\n",
    ")\n",
    "from glide_text2im.tokenizer.bpe import get_encoder\n",
    "from glide_text2im.xf import convert_module_to_f16\n",
    "\n",
    "from guided_diffusion.train_util import TrainLoop\n",
    "from guided_diffusion.gaussian_diffusion import ModelMeanType, ModelVarType, LossType\n",
    "from guided_diffusion.nn import mean_flat\n",
    "from guided_diffusion.losses import normal_kl, discretized_gaussian_log_likelihood\n",
    "from guided_diffusion.resample import create_named_schedule_sampler\n",
    "from guided_diffusion import dist_util, logger\n",
    "\n",
    "from guided_diffusion.respace import space_timesteps, SpacedDiffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0da56d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5ee5759",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = model_and_diffusion_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be1842bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "options['image_size'] = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c27e48d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_size': 256,\n",
       " 'num_channels': 192,\n",
       " 'num_res_blocks': 3,\n",
       " 'channel_mult': '',\n",
       " 'num_heads': 1,\n",
       " 'num_head_channels': 64,\n",
       " 'num_heads_upsample': -1,\n",
       " 'attention_resolutions': '32,16,8',\n",
       " 'dropout': 0.1,\n",
       " 'text_ctx': 128,\n",
       " 'xf_width': 512,\n",
       " 'xf_layers': 16,\n",
       " 'xf_heads': 8,\n",
       " 'xf_final_ln': True,\n",
       " 'xf_padding': True,\n",
       " 'diffusion_steps': 1000,\n",
       " 'noise_schedule': 'squaredcos_cap_v2',\n",
       " 'timestep_respacing': '',\n",
       " 'use_scale_shift_norm': True,\n",
       " 'resblock_updown': True,\n",
       " 'use_fp16': True,\n",
       " 'cache_text_emb': False,\n",
       " 'inpaint': False,\n",
       " 'super_res': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc0186af",
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults = dict(\n",
    "    data_dir=\"\",\n",
    "    schedule_sampler=\"uniform\",\n",
    "    lr=1e-4,\n",
    "    weight_decay=0.0,\n",
    "    lr_anneal_steps=0,\n",
    "    batch_size=1,\n",
    "    microbatch=-1,  # -1 disables microbatches\n",
    "    ema_rate=\"0.9999\",  # comma-separated list of EMA values\n",
    "    log_interval=10,\n",
    "    save_interval=10000,\n",
    "    resume_checkpoint=\"\",\n",
    "    use_fp16=options['use_fp16'],\n",
    "    fp16_scale_growth=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fee85e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaussian_diffusion(\n",
    "    *,\n",
    "    steps=1000,\n",
    "    learn_sigma=False,\n",
    "    sigma_small=False,\n",
    "    noise_schedule=\"linear\",\n",
    "    use_kl=False,\n",
    "    predict_xstart=False,\n",
    "    rescale_timesteps=False,\n",
    "    rescale_learned_sigmas=False,\n",
    "    timestep_respacing=\"\",\n",
    "):\n",
    "    '''\n",
    "    Copied from `https://github.com/openai/guided-diffusion/blob/main/guided_diffusion/script_util.py`.\n",
    "    Change `SpacedDiffusion` to our custom `TrainableSpacedDiffusion`.\n",
    "    '''\n",
    "    betas = get_named_beta_schedule(noise_schedule, steps)\n",
    "    if use_kl:\n",
    "        loss_type = LossType.RESCALED_KL\n",
    "    elif rescale_learned_sigmas:\n",
    "        loss_type = LossType.RESCALED_MSE\n",
    "    else:\n",
    "        loss_type = LossType.MSE\n",
    "    if not timestep_respacing:\n",
    "        timestep_respacing = [steps]\n",
    "    return SpacedDiffusion( # TrainableSpacedDiffusion(\n",
    "        use_timesteps=space_timesteps(steps, timestep_respacing),\n",
    "        betas=betas,\n",
    "        model_mean_type=(\n",
    "            ModelMeanType.EPSILON if not predict_xstart else ModelMeanType.START_X\n",
    "        ),\n",
    "        model_var_type=(\n",
    "            (\n",
    "                ModelVarType.FIXED_LARGE\n",
    "                if not sigma_small\n",
    "                else ModelVarType.FIXED_SMALL\n",
    "            )\n",
    "            if not learn_sigma\n",
    "            else ModelVarType.LEARNED_RANGE\n",
    "        ),\n",
    "        loss_type=loss_type,\n",
    "        rescale_timesteps=rescale_timesteps,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2ac4da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_and_diffusion(\n",
    "    image_size,\n",
    "    num_channels,\n",
    "    num_res_blocks,\n",
    "    channel_mult,\n",
    "    num_heads,\n",
    "    num_head_channels,\n",
    "    num_heads_upsample,\n",
    "    attention_resolutions,\n",
    "    dropout,\n",
    "    text_ctx,\n",
    "    xf_width,\n",
    "    xf_layers,\n",
    "    xf_heads,\n",
    "    xf_final_ln,\n",
    "    xf_padding,\n",
    "    diffusion_steps,\n",
    "    noise_schedule,\n",
    "    \n",
    "    learn_sigma,\n",
    "    sigma_small,\n",
    "    use_kl,\n",
    "    predict_xstart,\n",
    "    rescale_timesteps,\n",
    "    rescale_learned_sigmas,\n",
    "    \n",
    "    timestep_respacing,\n",
    "    use_scale_shift_norm,\n",
    "    resblock_updown,\n",
    "    use_fp16,\n",
    "    cache_text_emb,\n",
    "    inpaint,\n",
    "    super_res,\n",
    "):\n",
    "    '''\n",
    "    https://github.com/openai/glide-text2im/blob/9cc8e563851bd38f5ddb3e305127192cb0f02f5c/glide_text2im/model_creation.py#L54\n",
    "    '''\n",
    "    model = create_model(\n",
    "        image_size,\n",
    "        num_channels,\n",
    "        num_res_blocks,\n",
    "        channel_mult=channel_mult,\n",
    "        attention_resolutions=attention_resolutions,\n",
    "        num_heads=num_heads,\n",
    "        num_head_channels=num_head_channels,\n",
    "        num_heads_upsample=num_heads_upsample,\n",
    "        use_scale_shift_norm=use_scale_shift_norm,\n",
    "        dropout=dropout,\n",
    "        text_ctx=text_ctx,\n",
    "        xf_width=xf_width,\n",
    "        xf_layers=xf_layers,\n",
    "        xf_heads=xf_heads,\n",
    "        xf_final_ln=xf_final_ln,\n",
    "        xf_padding=xf_padding,\n",
    "        resblock_updown=resblock_updown,\n",
    "        use_fp16=use_fp16,\n",
    "        cache_text_emb=cache_text_emb,\n",
    "        inpaint=inpaint,\n",
    "        super_res=super_res,\n",
    "    )\n",
    "    diffusion = create_gaussian_diffusion(\n",
    "        steps=diffusion_steps,\n",
    "        noise_schedule=noise_schedule,\n",
    "        learn_sigma=learn_sigma,\n",
    "        sigma_small=sigma_small,\n",
    "        use_kl=use_kl,\n",
    "        predict_xstart=predict_xstart,\n",
    "        rescale_timesteps=rescale_timesteps,\n",
    "        rescale_learned_sigmas=rescale_learned_sigmas,\n",
    "        timestep_respacing=timestep_respacing,\n",
    "    )\n",
    "    return model, diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db8332dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, diffusion = create_model_and_diffusion(\n",
    "    **options, learn_sigma=True, sigma_small=False, use_kl=False, \n",
    "    predict_xstart=False, rescale_timesteps=False, rescale_learned_sigmas=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2c3a774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if options['use_fp16']:\n",
    "#     model.convert_to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7c95dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.Resize(img_size),\n",
    "     transforms.RandomCrop(img_size),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])]\n",
    ")\n",
    "valid_transform = transforms.Compose(\n",
    "    [transforms.Resize(img_size),\n",
    "     transforms.CenterCrop(img_size),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])]\n",
    ")\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# dataloader args\n",
    "parser.add_argument('--data-dir', type=str, default=\"../data\")\n",
    "parser.add_argument('--train-filename', type=str, default=\"../data/train.txt\")\n",
    "parser.add_argument('--valid-filename', type=str, default=\"../data/validation.txt\")\n",
    "parser.add_argument('--img-key', type=str, default=\"images\")\n",
    "parser.add_argument('--caption-key', type=str, default=\"captions\")\n",
    "parser.add_argument(\"--csv-separator\", type=str, default=\" \")\n",
    "parser.add_argument('--train-batch_size', type=int, default=defaults['batch_size'])\n",
    "parser.add_argument('--valid-batch-size', type=int, default=defaults['batch_size'])\n",
    "# transforms.ToTensor() changes input format from H x W x C to C x H x W\n",
    "# don't use below argument if input format required is C x H x W\n",
    "# use it to convert back from C x H x W\n",
    "# vqgan_jax requires H x W x C format, so set it to run this script\n",
    "parser.add_argument('--permute', action='store_true')\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = model.tokenizer.encode(text)\n",
    "    tokens, mask = model.tokenizer.padded_tokens_and_mask(\n",
    "        tokens, options['text_ctx']\n",
    "    )\n",
    "    cond = {'tokens': tokens, 'mask': mask}\n",
    "    return cond\n",
    "\n",
    "data = get_data(args, (train_transform, valid_transform), 'glide', tokenize=tokenize)\n",
    "data.setup()\n",
    "data = iter(data.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ba422cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_sampler = create_named_schedule_sampler(\"uniform\", diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17b6a435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to /tmp/openai-2022-03-02-16-32-32-734142\n"
     ]
    }
   ],
   "source": [
    "dist_util.setup_dist()\n",
    "logger.configure()\n",
    "\n",
    "model = model.to(dist_util.dev())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c1f89b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop = TrainLoop(\n",
    "    model=model,\n",
    "    diffusion=diffusion,\n",
    "    data=data,\n",
    "    batch_size=defaults['batch_size'],\n",
    "    microbatch=defaults['microbatch'],\n",
    "    lr=defaults['lr'],\n",
    "    ema_rate=defaults['ema_rate'],\n",
    "    log_interval=defaults['log_interval'],\n",
    "    save_interval=defaults['save_interval'],\n",
    "    resume_checkpoint=defaults['resume_checkpoint'],\n",
    "    use_fp16=defaults['use_fp16'],\n",
    "    fp16_scale_growth=defaults['fp16_scale_growth'],\n",
    "    schedule_sampler=schedule_sampler,\n",
    "    weight_decay=defaults['weight_decay'],\n",
    "    lr_anneal_steps=defaults['lr_anneal_steps'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5536b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "| grad_norm     | 4.32     |\n",
      "| lg_loss_scale | 20       |\n",
      "| loss          | 1.01     |\n",
      "| loss_q2       | 1.01     |\n",
      "| mse           | 1        |\n",
      "| mse_q2        | 1        |\n",
      "| param_norm    | 5.09e+03 |\n",
      "| samples       | 1        |\n",
      "| step          | 0        |\n",
      "| vb            | 0.00454  |\n",
      "| vb_q2         | 0.00454  |\n",
      "----------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "----------------------------\n",
      "| grad_norm     | 4        |\n",
      "| lg_loss_scale | 20       |\n",
      "| loss          | 0.867    |\n",
      "| loss_q0       | 0.893    |\n",
      "| loss_q1       | 0.867    |\n",
      "| loss_q2       | 0.869    |\n",
      "| loss_q3       | 0.848    |\n",
      "| mse           | 0.859    |\n",
      "| mse_q0        | 0.878    |\n",
      "| mse_q1        | 0.862    |\n",
      "| mse_q2        | 0.865    |\n",
      "| mse_q3        | 0.835    |\n",
      "| param_norm    | 5.09e+03 |\n",
      "| samples       | 11       |\n",
      "| step          | 10       |\n",
      "| vb            | 0.00717  |\n",
      "| vb_q0         | 0.0155   |\n",
      "| vb_q1         | 0.00439  |\n",
      "| vb_q2         | 0.00439  |\n",
      "| vb_q3         | 0.0127   |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 3.6      |\n",
      "| lg_loss_scale | 20       |\n",
      "| loss          | 0.642    |\n",
      "| loss_q0       | 0.726    |\n",
      "| loss_q1       | 0.621    |\n",
      "| loss_q2       | 0.566    |\n",
      "| loss_q3       | 0.647    |\n",
      "| mse           | 0.621    |\n",
      "| mse_q0        | 0.712    |\n",
      "| mse_q1        | 0.618    |\n",
      "| mse_q2        | 0.563    |\n",
      "| mse_q3        | 0.606    |\n",
      "| param_norm    | 5.09e+03 |\n",
      "| samples       | 21       |\n",
      "| step          | 20       |\n",
      "| vb            | 0.0207   |\n",
      "| vb_q0         | 0.0146   |\n",
      "| vb_q1         | 0.00306  |\n",
      "| vb_q2         | 0.00288  |\n",
      "| vb_q3         | 0.0416   |\n",
      "----------------------------\n",
      "Found NaN, decreased lg_loss_scale to 19.023000000000028\n",
      "----------------------------\n",
      "| grad_norm     | 2.94     |\n",
      "| lg_loss_scale | 19.3     |\n",
      "| loss          | 0.461    |\n",
      "| loss_q0       | 0.616    |\n",
      "| loss_q1       | 0.44     |\n",
      "| loss_q2       | 0.352    |\n",
      "| loss_q3       | 0.42     |\n",
      "| mse           | 0.455    |\n",
      "| mse_q0        | 0.601    |\n",
      "| mse_q1        | 0.437    |\n",
      "| mse_q2        | 0.351    |\n",
      "| mse_q3        | 0.417    |\n",
      "| param_norm    | 5.09e+03 |\n",
      "| samples       | 31       |\n",
      "| step          | 30       |\n",
      "| vb            | 0.00529  |\n",
      "| vb_q0         | 0.015    |\n",
      "| vb_q1         | 0.00231  |\n",
      "| vb_q2         | 0.00185  |\n",
      "| vb_q3         | 0.00392  |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 3.3      |\n",
      "| lg_loss_scale | 19       |\n",
      "| loss          | 0.403    |\n",
      "| loss_q0       | 0.689    |\n",
      "| loss_q2       | 0.274    |\n",
      "| loss_q3       | 0.29     |\n",
      "| mse           | 0.387    |\n",
      "| mse_q0        | 0.648    |\n",
      "| mse_q2        | 0.273    |\n",
      "| mse_q3        | 0.277    |\n",
      "| param_norm    | 5.09e+03 |\n",
      "| samples       | 41       |\n",
      "| step          | 40       |\n",
      "| vb            | 0.0168   |\n",
      "| vb_q0         | 0.0405   |\n",
      "| vb_q2         | 0.00156  |\n",
      "| vb_q3         | 0.0134   |\n",
      "----------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nfs/data/andrewbai/Natural-Disaster-Image-Generation-to-raise-Environmental-Awareness/guided-diffusion/guided_diffusion/train_util.py:159\u001b[0m, in \u001b[0;36mTrainLoop.run_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_anneal_steps\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_step \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_anneal_steps\n\u001b[1;32m    157\u001b[0m ):\n\u001b[1;32m    158\u001b[0m     batch, cond \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    161\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdumpkvs()\n",
      "File \u001b[0;32m/nfs/data/andrewbai/Natural-Disaster-Image-Generation-to-raise-Environmental-Awareness/guided-diffusion/guided_diffusion/train_util.py:173\u001b[0m, in \u001b[0;36mTrainLoop.run_step\u001b[0;34m(self, batch, cond)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, cond):\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     took_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmp_trainer\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt)\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m took_step:\n",
      "File \u001b[0;32m/nfs/data/andrewbai/Natural-Disaster-Image-Generation-to-raise-Environmental-Awareness/guided-diffusion/guided_diffusion/train_util.py:214\u001b[0m, in \u001b[0;36mTrainLoop.forward_backward\u001b[0;34m(self, batch, cond)\u001b[0m\n\u001b[1;32m    210\u001b[0m loss \u001b[38;5;241m=\u001b[39m (losses[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m weights)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    211\u001b[0m log_loss_dict(\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffusion, t, {k: v \u001b[38;5;241m*\u001b[39m weights \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m losses\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    213\u001b[0m )\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmp_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nfs/data/andrewbai/Natural-Disaster-Image-Generation-to-raise-Environmental-Awareness/guided-diffusion/guided_diffusion/fp16_util.py:179\u001b[0m, in \u001b[0;36mMixedPrecisionTrainer.backward\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_fp16:\n\u001b[1;32m    178\u001b[0m     loss_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlg_loss_scale\n\u001b[0;32m--> 179\u001b[0m     \u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_scale\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/t2i/lib/python3.8/site-packages/torch/_tensor.py:255\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    248\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    249\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    254\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 255\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/t2i/lib/python3.8/site-packages/torch/autograd/__init__.py:147\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 147\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loop.run_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7971ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def run_loop(self):\n",
    "    while (\n",
    "        not self.lr_anneal_steps\n",
    "        or self.step + self.resume_step < self.lr_anneal_steps\n",
    "    ):\n",
    "        batch, cond = next(self.data)\n",
    "        self.run_step(batch, cond)\n",
    "        if self.step % self.log_interval == 0:\n",
    "            logger.dumpkvs()\n",
    "        if self.step % self.save_interval == 0:\n",
    "            self.save()\n",
    "            # Run for a finite amount of time in integration tests.\n",
    "            if os.environ.get(\"DIFFUSION_TRAINING_TEST\", \"\") and self.step > 0:\n",
    "                return\n",
    "        self.step += 1\n",
    "    # Save the last checkpoint if it wasn't already saved.\n",
    "    if (self.step - 1) % self.save_interval != 0:\n",
    "        self.save()\n",
    "        \n",
    "def run_step(self, batch, cond):\n",
    "    self.forward_backward(batch, cond)\n",
    "    took_step = self.mp_trainer.optimize(self.opt)\n",
    "    if took_step:\n",
    "        self._update_ema()\n",
    "    self._anneal_lr()\n",
    "    self.log_step()\n",
    "\n",
    "def forward_backward(self, batch, cond):\n",
    "    self.mp_trainer.zero_grad()\n",
    "    for i in range(0, batch.shape[0], self.microbatch):\n",
    "        micro = batch[i : i + self.microbatch].to(dist_util.dev())\n",
    "        micro_cond = {\n",
    "            k: v[i : i + self.microbatch].to(dist_util.dev())\n",
    "            for k, v in cond.items()\n",
    "        }\n",
    "        last_batch = (i + self.microbatch) >= batch.shape[0]\n",
    "        t, weights = self.schedule_sampler.sample(micro.shape[0], dist_util.dev())\n",
    "\n",
    "        compute_losses = functools.partial(\n",
    "            self.diffusion.training_losses,\n",
    "            self.ddp_model,\n",
    "            micro,\n",
    "            t,\n",
    "            model_kwargs=micro_cond,\n",
    "        )\n",
    "\n",
    "        if last_batch or not self.use_ddp:\n",
    "            losses = compute_losses()\n",
    "        else:\n",
    "            with self.ddp_model.no_sync():\n",
    "                losses = compute_losses()\n",
    "\n",
    "        if isinstance(self.schedule_sampler, LossAwareSampler):\n",
    "            self.schedule_sampler.update_with_local_losses(\n",
    "                t, losses[\"loss\"].detach()\n",
    "            )\n",
    "\n",
    "        loss = (losses[\"loss\"] * weights).mean()\n",
    "        log_loss_dict(\n",
    "            self.diffusion, t, {k: v * weights for k, v in losses.items()}\n",
    "        )\n",
    "        self.mp_trainer.backward(loss)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "562bfef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, cond = next(train_loop.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "060c2c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.to(dist_util.dev())\n",
    "cond = {\n",
    "    k: v.to(dist_util.dev())\n",
    "    for k, v in cond.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad758da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop.run_step(batch, cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5473cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop.forward_backward(batch, cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58c39454",
   "metadata": {},
   "outputs": [],
   "source": [
    "took_step = train_loop.mp_trainer.optimize(train_loop.opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5cec7283",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, weights = train_loop.schedule_sampler.sample(batch.shape[0], dist_util.dev())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21288be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_losses = functools.partial(\n",
    "    train_loop.diffusion.training_losses,\n",
    "    train_loop.ddp_model,\n",
    "    batch,\n",
    "    t,\n",
    "    model_kwargs=cond,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ecfdce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = compute_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9858056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vb': tensor([0.0667], device='cuda:0', grad_fn=<SWhereBackward>),\n",
       " 'mse': tensor([0.9988], device='cuda:0', grad_fn=<MeanBackward1>),\n",
       " 'loss': tensor([1.0654], device='cuda:0', grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fc41620",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (losses[\"loss\"] * weights).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02c39fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop.mp_trainer.backward(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e9b048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "took_step = train_loop.mp_trainer.optimize(train_loop.opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "158ebb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "took_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "ae34fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn_like(batch)\n",
    "x_t = train_loop.diffusion.q_sample(batch, t, noise=noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "0217fc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "50dc9750",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_t = train_loop.diffusion._scale_timesteps(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "7d7f7cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([164], device='cuda:0') tensor([164], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(scaled_t, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589cd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x, timesteps, tokens=None, mask=None):\n",
    "        hs = []\n",
    "        emb = self.time_embed(timestep_embedding(timesteps, self.model_channels))\n",
    "        if self.xf_width:\n",
    "            text_outputs = self.get_text_emb(tokens, mask)\n",
    "            xf_proj, xf_out = text_outputs[\"xf_proj\"], text_outputs[\"xf_out\"]\n",
    "            emb = emb + xf_proj.to(emb)\n",
    "        else:\n",
    "            xf_out = None\n",
    "        h = x.type(self.dtype)\n",
    "        for module in self.input_blocks:\n",
    "            h = module(h, emb, xf_out)\n",
    "            hs.append(h)\n",
    "        h = self.middle_block(h, emb, xf_out)\n",
    "        for module in self.output_blocks:\n",
    "            h = th.cat([h, hs.pop()], dim=1)\n",
    "            h = module(h, emb, xf_out)\n",
    "        h = h.type(x.dtype)\n",
    "        h = self.out(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "1b7dca49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = train_loop.model.time_embed(timestep_embedding(scaled_t, train_loop.model.model_channels))\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "0b3288c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf_in = train_loop.model.token_embedding(cond['tokens'].long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "66212ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loop.model.padding_embedding[None].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "98b84673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xf_in.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "384cc5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf_in = torch.where(cond['mask'][..., None], xf_in, train_loop.model.padding_embedding[None].to(torch.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "b8dbf748",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf_out = train_loop.model.transformer(xf_in.to(train_loop.model.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "50f75cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf_out = train_loop.model.final_ln(xf_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "d1bf169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf_proj = train_loop.model.transformer_proj(xf_out[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "48a40652",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf_out = xf_out.permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "bb6a5fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_outputs = dict(xf_proj=xf_proj, xf_out=xf_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "a2888d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf_proj, xf_out = text_outputs[\"xf_proj\"], text_outputs[\"xf_out\"]\n",
    "emb = emb + xf_proj.to(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "0818465f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.8044e-01,  1.0896e+00, -2.1173e-01, -6.7466e-01,  1.2109e-01,\n",
       "         -1.0182e+00,  3.3557e-01,  1.2053e-01,  4.7135e-01,  4.6891e-01,\n",
       "         -2.3416e-01, -2.4081e-01,  2.1960e-01,  7.8206e-01,  5.8388e-01,\n",
       "         -5.7195e-01, -1.7002e-01,  1.6693e-01, -1.9188e-01,  2.0491e-01,\n",
       "         -2.0205e-01, -1.2121e-01, -4.7672e-01,  7.2354e-01, -1.1115e-01,\n",
       "         -1.8986e-01, -3.9922e-01, -1.2227e+00, -3.5668e-01, -5.0049e-01,\n",
       "         -4.0665e-01,  3.5411e-01,  5.6386e-01, -7.2206e-01, -3.0089e-01,\n",
       "          1.1960e-01,  8.4087e-01, -9.3811e-01,  2.3384e-01,  8.7181e-01,\n",
       "          2.2939e-01,  4.2666e-01,  1.4032e-01,  1.0607e+00, -5.5759e-01,\n",
       "         -6.1131e-01, -1.3434e-01, -8.0868e-01,  8.8383e-02, -9.3230e-02,\n",
       "          4.0284e-01,  3.6635e-01,  4.4648e-01,  5.7132e-02,  6.7303e-01,\n",
       "          3.2172e-01, -3.0984e-01, -8.0393e-02, -1.8968e-01, -8.5095e-03,\n",
       "         -7.9837e-01, -7.4838e-02, -1.1586e+00,  1.7473e-01,  2.9347e-02,\n",
       "          2.0359e-01,  3.8169e-01, -5.9537e-02, -2.5930e-01, -7.0236e-01,\n",
       "          6.6356e-01, -1.3903e+00, -5.6046e-01, -9.8420e-01, -7.7844e-01,\n",
       "         -4.6039e-01,  2.6329e-01, -8.3832e-01, -2.2496e-01,  3.1435e-01,\n",
       "          4.5310e-02, -8.9028e-01,  5.6153e-01,  4.2312e-01,  2.1462e-01,\n",
       "         -6.6507e-01, -4.8025e-01,  3.5682e-01, -2.6378e-01,  2.6013e-01,\n",
       "         -1.8174e-03,  5.3156e-01,  9.2130e-01, -3.6670e-01, -3.5743e-01,\n",
       "         -3.1595e-01,  1.3617e+00, -7.8474e-02,  1.6927e-01, -6.7867e-01,\n",
       "         -1.8261e-01, -1.1882e+00, -2.1803e-01,  5.5528e-01, -7.6649e-01,\n",
       "          4.5619e-01,  1.8093e-01, -5.9775e-02,  7.8862e-01, -4.8392e-01,\n",
       "         -4.5563e-01, -9.2173e-01,  3.6047e-01,  2.7539e-01, -1.6486e-01,\n",
       "         -1.8038e-01,  3.8507e-01, -5.7623e-01,  7.2022e-02, -3.0926e-01,\n",
       "          4.1260e-01,  4.4629e-01, -3.3675e-01,  3.0846e-01,  5.8047e-01,\n",
       "         -7.5150e-01,  7.0773e-01, -5.1330e-02, -3.1018e-01, -4.5459e-01,\n",
       "         -8.6418e-01,  2.1661e-01, -1.4962e+00, -8.9639e-01, -3.1202e-01,\n",
       "          2.3227e-01, -3.7514e-02, -5.8813e-01,  8.5282e-01, -8.5988e-02,\n",
       "          1.1166e+00,  2.0391e-01,  1.8991e-01,  1.1420e-01,  1.6565e-02,\n",
       "          1.5008e-01, -8.5896e-01, -1.2719e+00, -6.5455e-01,  6.9568e-01,\n",
       "         -1.0758e-01,  6.1961e-02,  2.7163e-01, -8.2395e-01, -2.0771e-01,\n",
       "         -7.9350e-01, -9.6754e-01,  5.1112e-02,  3.1864e-01, -7.9331e-02,\n",
       "          1.5771e-01,  1.4198e+00,  2.1235e-01,  7.4285e-02,  1.6446e-01,\n",
       "         -8.9102e-01, -2.8417e-01, -2.5999e-01, -1.4702e-01,  1.4072e-01,\n",
       "          7.5971e-01, -6.6839e-01,  3.7195e-01, -1.2613e-01,  3.5825e-02,\n",
       "          6.8219e-01,  1.6385e-01,  7.3160e-01, -1.2315e+00, -4.4039e-01,\n",
       "         -9.2290e-01, -2.7366e-01,  3.6175e-01, -1.3066e-01, -6.7001e-01,\n",
       "         -2.3428e-01, -4.1145e-01, -5.0612e-02, -4.2527e-01,  5.7298e-01,\n",
       "          1.0507e-01, -2.3682e-01, -6.9166e-01,  6.2889e-01, -2.6354e-01,\n",
       "         -4.1668e-01,  3.2635e-01,  8.6001e-02,  1.2520e+00, -4.0543e-01,\n",
       "          6.6489e-01, -4.2885e-01,  2.7097e-01,  2.3295e-01,  1.7304e-01,\n",
       "         -7.3533e-01, -8.6323e-01, -8.7255e-02,  4.6221e-01, -2.4528e-01,\n",
       "          9.2268e-01,  3.7081e-01, -9.2418e-02, -3.8476e-01, -2.3071e-01,\n",
       "          9.6531e-01, -4.1787e-01,  3.7398e-01, -5.4782e-01,  2.8582e-01,\n",
       "         -7.8790e-01,  2.8184e-01,  8.6999e-01, -5.2598e-01,  3.6950e-02,\n",
       "         -1.9367e+00, -2.1556e-01, -5.2588e-01, -2.9569e-02, -5.9247e-02,\n",
       "          6.0384e-01, -8.1044e-01, -1.7688e-01, -4.4221e-01,  2.5650e-01,\n",
       "         -8.6809e-02,  1.3400e-01,  7.3718e-02,  3.2212e-01,  7.5039e-01,\n",
       "          4.2370e-01, -3.5131e-01,  1.1675e+00,  2.5710e-01, -9.8824e-01,\n",
       "          1.0493e+00, -4.0782e-01,  5.7177e-01, -1.7012e-01,  3.0883e-02,\n",
       "          4.7865e-01, -3.7718e-01,  8.6308e-01,  9.4678e-01, -3.6520e-01,\n",
       "         -1.1859e-01,  2.6327e-01, -1.9562e-01,  1.1937e+00, -1.1170e+00,\n",
       "         -3.4036e-01, -9.5623e-02, -2.3957e-01,  3.1494e-01,  8.2166e-01,\n",
       "         -1.9793e-01, -5.8487e-01, -3.0745e-01,  9.2250e-01, -2.7480e-01,\n",
       "         -2.6119e-01,  1.3441e+00, -4.0271e-01,  8.6611e-01,  6.2971e-01,\n",
       "         -2.6280e-01,  2.2298e-02,  1.8356e-01,  3.4055e-01, -1.8321e-01,\n",
       "         -6.6002e-01,  1.1368e+00, -3.6336e-01,  1.2536e+00, -1.3271e+00,\n",
       "         -2.4629e-01,  6.0141e-01, -1.3096e-01, -2.9087e-02, -6.5598e-01,\n",
       "         -5.8457e-01,  3.0219e-01, -7.1051e-01, -2.3300e-01,  5.2829e-01,\n",
       "         -2.8017e-02,  5.1359e-02, -8.1897e-01,  1.0663e+00,  1.6690e-01,\n",
       "          5.3175e-01,  9.4915e-01, -7.2137e-01, -5.0731e-01,  1.6836e-01,\n",
       "          8.4025e-01, -4.8670e-01,  1.3313e+00, -6.2098e-01, -2.2795e-01,\n",
       "         -4.5478e-01,  6.3734e-01, -7.8303e-01, -1.9516e-01, -3.7204e-01,\n",
       "         -1.9223e-01, -2.2164e-01,  4.4795e-01, -5.5079e-01,  2.3186e-01,\n",
       "          2.7571e-01, -2.6663e-01, -1.0286e+00, -7.1519e-01, -5.9764e-01,\n",
       "         -9.9233e-02, -2.1213e-01, -1.8701e-01, -7.4979e-01, -2.7880e-01,\n",
       "         -5.2886e-01, -2.2081e-01, -3.7181e-01, -1.0975e+00,  7.1425e-01,\n",
       "         -3.1105e-01, -3.2025e-01,  6.2634e-01,  1.0165e+00, -2.7600e-02,\n",
       "         -1.1075e+00,  7.5679e-01,  4.0363e-01, -4.2636e-01, -1.6186e-01,\n",
       "          4.2582e-01, -1.5244e-02,  4.9491e-01, -2.8661e-01, -1.0027e+00,\n",
       "          9.8695e-01,  5.6924e-01,  3.1942e-02, -5.3759e-02,  3.9753e-01,\n",
       "          5.5518e-01,  9.4280e-02, -7.8804e-01,  2.3708e-01,  3.0135e-01,\n",
       "          8.3312e-01,  6.5020e-01,  9.1786e-01,  9.4288e-01, -1.1449e+00,\n",
       "          5.6396e-01,  5.8893e-01,  1.1922e+00,  3.0684e-01, -8.8291e-01,\n",
       "         -8.1287e-02,  1.8776e-01,  2.0544e-01, -2.4494e-01, -3.7228e-01,\n",
       "          4.5986e-01,  3.7520e-01,  2.2872e-01, -2.0544e-01,  8.7541e-02,\n",
       "          2.3856e-01,  7.6133e-01,  1.1272e-01,  3.7811e-01,  5.0752e-01,\n",
       "         -1.3195e-01, -2.6895e-01, -5.3109e-02,  8.4503e-02,  3.9388e-01,\n",
       "         -2.9535e-01,  1.4280e+00, -2.7012e-01,  5.4060e-02, -3.9824e-01,\n",
       "          9.5464e-01,  6.0839e-01, -4.5086e-01,  4.2153e-01,  2.9817e-01,\n",
       "         -6.0786e-01, -4.2714e-03, -5.6741e-01,  4.0281e-01,  1.4779e-01,\n",
       "         -4.5557e-01,  3.1066e-01,  5.8539e-02,  2.2097e-01,  6.2747e-01,\n",
       "         -3.9359e-01, -2.3798e-01, -6.0024e-01,  5.7786e-01,  7.5156e-01,\n",
       "          3.3522e-01, -7.2515e-01,  7.0054e-01, -1.4459e-01,  2.8607e-01,\n",
       "         -4.5283e-01, -5.3466e-01, -2.8859e-01,  1.8375e-01,  1.9848e-02,\n",
       "         -1.0414e-01, -1.5478e-01,  5.1939e-02,  3.8824e-01, -6.8944e-01,\n",
       "         -2.6867e-01, -2.5287e-01,  6.8308e-01, -4.7823e-01,  2.3987e-01,\n",
       "         -7.7120e-01,  2.5118e-01,  5.7350e-01, -5.8737e-01,  4.9753e-01,\n",
       "          4.8783e-01,  2.1057e-01, -8.0006e-01,  7.7201e-01,  8.1020e-02,\n",
       "         -6.6070e-01, -6.7588e-01, -1.2665e-01,  2.6830e-01,  7.4914e-01,\n",
       "         -2.7370e-01,  3.8452e-01, -2.1324e-01, -4.1554e-01,  5.3425e-01,\n",
       "          2.7034e-01,  5.5118e-01, -4.6483e-01,  1.1987e-01,  2.5016e-01,\n",
       "         -6.4195e-02,  4.2901e-01,  4.3971e-01,  3.7481e-01, -1.0623e+00,\n",
       "          4.9380e-01, -3.6742e-01, -4.6205e-01, -9.1471e-01, -7.2564e-01,\n",
       "         -5.6829e-02,  6.4573e-01, -9.9160e-02,  1.3540e-01, -9.6848e-01,\n",
       "          9.2899e-01,  1.2597e-01,  2.5039e-01, -4.6172e-01,  5.4161e-02,\n",
       "          6.7912e-02,  5.8112e-01,  4.4945e-01,  1.1777e+00, -1.7970e-01,\n",
       "          9.2753e-01, -2.5905e-01,  1.2393e+00,  1.7185e-01,  2.3061e-01,\n",
       "         -1.1156e+00,  1.2958e-01, -2.0486e-01,  8.0200e-01, -5.1824e-01,\n",
       "         -9.6147e-02,  4.4624e-02,  2.7136e-01,  3.0266e-01,  1.1392e-01,\n",
       "         -5.7463e-01, -1.0535e+00, -2.6410e-01, -7.1090e-01,  9.1894e-01,\n",
       "         -4.8341e-01,  4.7957e-01,  4.9187e-01,  9.4392e-02,  6.7721e-01,\n",
       "         -8.5299e-01, -2.2072e-01, -2.1986e+00, -2.3577e-01,  1.0805e+00,\n",
       "          1.3853e-01, -8.5922e-01, -3.4150e-01,  6.5294e-03, -6.3353e-01,\n",
       "         -4.0881e-02,  4.4508e-02, -4.8519e-01,  3.7850e-01,  9.7500e-02,\n",
       "          5.9077e-01,  1.7830e-01,  4.9747e-01, -1.3099e-01,  4.0973e-02,\n",
       "         -8.3618e-01,  3.5610e-01,  4.2240e-01,  2.9012e-01,  9.2429e-02,\n",
       "         -1.0075e+00, -4.1077e-02, -5.1236e-01, -4.6687e-01, -8.6681e-01,\n",
       "         -2.6267e-01, -6.6943e-01,  1.3364e-01, -1.2945e-01,  2.1266e-02,\n",
       "         -4.4273e-01, -5.4260e-01, -4.8650e-01, -4.0005e-01, -7.6323e-03,\n",
       "         -4.1990e-03, -7.9178e-01, -8.3458e-01, -4.9081e-02,  1.4296e+00,\n",
       "         -8.2659e-02,  7.3734e-01,  2.8373e-01,  7.7579e-01, -7.2355e-01,\n",
       "         -4.2166e-01, -4.8902e-01,  3.1815e-02,  2.9873e-01, -4.0965e-01,\n",
       "         -5.9256e-01, -2.2808e-01,  9.2898e-01, -4.2937e-01, -4.3237e-01,\n",
       "          1.3288e-01,  7.6508e-03,  3.1444e-01, -5.0724e-01,  1.1429e+00,\n",
       "         -6.7171e-01,  6.8398e-02, -5.9911e-02, -3.0369e-01, -4.7480e-01,\n",
       "          8.2107e-02,  9.3202e-01,  2.1477e-01,  1.4370e-01,  6.1436e-01,\n",
       "         -2.3807e-01,  5.2045e-01,  6.2563e-01, -1.3314e+00,  5.3790e-01,\n",
       "          8.2587e-01, -1.0839e+00,  4.8089e-01,  1.1896e+00, -4.9948e-01,\n",
       "          2.0755e-01,  3.8068e-01,  1.8866e-01,  2.4752e-01, -7.2498e-01,\n",
       "         -5.9300e-01,  3.2018e-02,  8.5624e-01, -7.6696e-01,  5.4720e-01,\n",
       "          5.5757e-01, -7.7452e-01, -6.0049e-01, -6.0409e-01, -3.4715e-01,\n",
       "          4.0648e-01, -3.4992e-01, -2.4925e-01,  1.2358e-01, -2.1519e-02,\n",
       "          4.9221e-01,  3.9971e-01, -3.5572e-01, -1.3741e+00,  1.6617e-01,\n",
       "         -1.0486e+00,  2.9607e-01, -3.4700e-01, -6.8829e-01,  3.5434e-01,\n",
       "         -2.4792e-01,  1.5984e-01, -4.0600e-01, -5.8137e-02, -5.9791e-01,\n",
       "         -5.9802e-01,  3.4905e-01, -4.3848e-01,  4.3696e-02,  4.8997e-01,\n",
       "         -3.1603e-01,  2.1499e-01, -2.3377e-01, -1.6120e+00, -1.1016e+00,\n",
       "         -4.0848e-01,  3.1723e-01,  3.4430e-02, -3.8058e-02, -6.5914e-01,\n",
       "         -3.5389e-01, -3.7222e-01, -5.7032e-01,  8.0738e-01,  6.8904e-01,\n",
       "          2.0321e-01, -2.2919e-01,  3.4457e-01, -6.1700e-01,  7.6257e-01,\n",
       "         -5.6803e-02, -1.8372e-01,  1.0571e+00,  2.6151e-01, -8.3431e-01,\n",
       "          3.7099e-01,  1.8551e-01,  2.4025e-01, -1.1378e+00,  1.1742e+00,\n",
       "          2.6943e-01, -6.3056e-01,  6.6232e-02, -1.2651e-01,  2.0150e-01,\n",
       "          1.3841e-01, -4.5424e-01,  1.8137e-01,  6.8641e-01,  4.3034e-01,\n",
       "          3.1300e-01, -2.4686e-01, -7.6623e-01,  1.2218e-01,  7.7329e-02,\n",
       "          2.2547e-01,  7.0082e-01,  1.3017e-01,  5.1460e-01, -2.7870e-01,\n",
       "         -2.4325e-01, -4.5382e-01, -3.6399e-01, -6.9238e-01,  4.3787e-01,\n",
       "          9.2270e-01, -3.3979e-01,  4.6841e-01,  1.0128e-01, -5.0765e-01,\n",
       "          2.7804e-01, -1.2401e-01, -4.1858e-01,  2.2965e-01, -4.5999e-01,\n",
       "          5.3422e-01,  5.9782e-01, -1.9300e-01, -5.5484e-01, -2.0765e-01,\n",
       "          3.1090e-01, -7.7288e-01,  9.0279e-01, -1.2404e+00, -3.2111e-01,\n",
       "          6.6805e-01,  1.2692e-01,  1.3481e+00,  3.2711e-01, -1.1260e-01,\n",
       "         -5.7465e-01, -6.2476e-01,  4.4945e-01, -8.1844e-01,  3.3281e-01,\n",
       "         -4.4370e-01, -2.8883e-01, -2.0678e-01,  3.5442e-01,  2.6974e-01,\n",
       "         -8.0086e-01,  8.9113e-01, -1.3252e+00, -3.3250e-01, -3.2844e-01,\n",
       "         -9.1023e-03, -1.1143e+00, -3.7205e-01, -1.9938e-01,  3.6164e-01,\n",
       "          1.5002e+00, -2.5092e-01,  2.7448e-01, -1.5603e-01,  8.5593e-01,\n",
       "          4.1898e-01, -4.3764e-01, -6.2768e-01, -6.9498e-01,  2.0785e-01,\n",
       "         -2.6454e-01,  5.7751e-01, -7.5172e-01,  2.3494e-01,  9.3062e-01,\n",
       "          7.5156e-01, -8.4539e-02,  5.6650e-01,  1.7044e-01,  1.0382e-01,\n",
       "         -2.5780e-01,  1.9817e-01,  7.8343e-01,  3.6524e-01, -6.8780e-03,\n",
       "         -7.6221e-01, -3.6658e-01,  4.0071e-01, -5.4438e-02,  2.8723e-02,\n",
       "          8.7387e-01, -5.1714e-01, -6.3579e-02]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "b5db826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = batch.type(train_loop.model.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "36a61355",
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "f9743283",
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in train_loop.model.input_blocks:\n",
    "    h = module(h, emb, xf_out)\n",
    "    hs.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "3cef9c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = train_loop.model.middle_block(h, emb, xf_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "cf3aaf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in train_loop.model.output_blocks:\n",
    "    h = torch.cat([h, hs.pop()], dim=1)\n",
    "    h = module(h, emb, xf_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "36dad7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "4991d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = h.type(batch.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "159663b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "68375ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0950,  0.1895,  0.1876,  ..., -0.2178, -0.1205, -0.0816],\n",
       "          [ 0.1599,  0.2959,  0.2949,  ..., -0.1941, -0.0786, -0.0690],\n",
       "          [ 0.1593,  0.3059,  0.2979,  ..., -0.0363,  0.0039,  0.0089],\n",
       "          ...,\n",
       "          [ 0.1442,  0.2322,  0.2067,  ...,  0.0978,  0.0929,  0.0916],\n",
       "          [ 0.1343,  0.2094,  0.2346,  ...,  0.0778,  0.1064,  0.0715],\n",
       "          [ 0.0995,  0.1720,  0.1879,  ...,  0.0553,  0.0612,  0.0157]],\n",
       "\n",
       "         [[ 0.1814,  0.3132,  0.3059,  ..., -0.2178, -0.1222, -0.0175],\n",
       "          [ 0.2476,  0.4126,  0.4036,  ..., -0.2080, -0.1019, -0.0074],\n",
       "          [ 0.2529,  0.4202,  0.4089,  ..., -0.0117,  0.0224,  0.0509],\n",
       "          ...,\n",
       "          [ 0.2236,  0.3542,  0.3059,  ...,  0.1700,  0.1682,  0.0909],\n",
       "          [ 0.2048,  0.3564,  0.3418,  ...,  0.1592,  0.1703,  0.0845],\n",
       "          [ 0.1147,  0.2013,  0.2026,  ...,  0.0837,  0.0842,  0.0389]],\n",
       "\n",
       "         [[ 0.0740,  0.1656,  0.1617,  ..., -0.2262, -0.1884, -0.1265],\n",
       "          [ 0.0842,  0.2595,  0.2505,  ..., -0.2690, -0.2195, -0.1105],\n",
       "          [ 0.0884,  0.2598,  0.2581,  ..., -0.1433, -0.0831, -0.0530],\n",
       "          ...,\n",
       "          [ 0.0846,  0.2644,  0.2117,  ...,  0.0973,  0.1014,  0.0959],\n",
       "          [ 0.0769,  0.2461,  0.2188,  ...,  0.0908,  0.1071,  0.1119],\n",
       "          [ 0.0085,  0.0898,  0.1027,  ..., -0.0016, -0.0030,  0.0352]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1505, -0.1635, -0.1569,  ...,  0.2162,  0.1494,  0.1367],\n",
       "          [ 0.0898,  0.0304,  0.0362,  ...,  0.0683,  0.1149,  0.1792],\n",
       "          [ 0.0803,  0.0325,  0.0370,  ...,  0.0304,  0.0258,  0.1008],\n",
       "          ...,\n",
       "          [ 0.0946, -0.0021, -0.0303,  ...,  0.0853,  0.0682,  0.0516],\n",
       "          [ 0.1047,  0.0203, -0.0081,  ...,  0.1696,  0.1600,  0.0883],\n",
       "          [ 0.1980,  0.1395,  0.0931,  ...,  0.1277,  0.1439,  0.0951]],\n",
       "\n",
       "         [[-0.1404, -0.0673, -0.0735,  ..., -0.1781, -0.2300, -0.1292],\n",
       "          [-0.1289, -0.1428, -0.1340,  ..., -0.0994, -0.0483, -0.0754],\n",
       "          [-0.1284, -0.1370, -0.1318,  ..., -0.0490, -0.0649, -0.0559],\n",
       "          ...,\n",
       "          [-0.1250, -0.1488, -0.1348,  ..., -0.1216, -0.1163, -0.1394],\n",
       "          [-0.1370, -0.1396, -0.1355,  ..., -0.1536, -0.1713, -0.1775],\n",
       "          [-0.1212, -0.1775, -0.1608,  ..., -0.1257, -0.0945, -0.1467]],\n",
       "\n",
       "         [[ 0.1714,  0.1732,  0.1718,  ..., -0.0406,  0.0052,  0.0031],\n",
       "          [ 0.0878,  0.0734,  0.0718,  ...,  0.0823,  0.0547,  0.0654],\n",
       "          [ 0.0939,  0.0799,  0.0699,  ...,  0.1156,  0.0936,  0.1144],\n",
       "          ...,\n",
       "          [ 0.0975,  0.0947,  0.1337,  ...,  0.0717,  0.0907,  0.1151],\n",
       "          [ 0.0848,  0.0681,  0.1266,  ...,  0.0765,  0.0684,  0.0677],\n",
       "          [-0.0216, -0.0220, -0.0249,  ...,  0.0551,  0.0550,  0.0585]]]],\n",
       "       device='cuda:0', grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "e077a99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0497,  0.1037,  0.1026,  ..., -0.0971, -0.0566, -0.0391],\n",
       "          [ 0.0863,  0.1697,  0.1690,  ..., -0.0877, -0.0377, -0.0333],\n",
       "          [ 0.0860,  0.1762,  0.1709,  ..., -0.0178,  0.0019,  0.0044],\n",
       "          ...,\n",
       "          [ 0.0773,  0.1295,  0.1140,  ...,  0.0513,  0.0486,  0.0479],\n",
       "          [ 0.0716,  0.1156,  0.1310,  ...,  0.0404,  0.0561,  0.0370],\n",
       "          [ 0.0522,  0.0934,  0.1027,  ...,  0.0284,  0.0316,  0.0079]],\n",
       "\n",
       "         [[ 0.0989,  0.1809,  0.1762,  ..., -0.0971, -0.0574, -0.0087],\n",
       "          [ 0.1390,  0.2483,  0.2420,  ..., -0.0932, -0.0483, -0.0037],\n",
       "          [ 0.1424,  0.2536,  0.2457,  ..., -0.0058,  0.0113,  0.0261],\n",
       "          ...,\n",
       "          [ 0.1243,  0.2082,  0.1762,  ...,  0.0922,  0.0912,  0.0475],\n",
       "          [ 0.1129,  0.2097,  0.1998,  ...,  0.0859,  0.0924,  0.0440],\n",
       "          [ 0.0607,  0.1107,  0.1115,  ...,  0.0436,  0.0439,  0.0198]],\n",
       "\n",
       "         [[ 0.0384,  0.0897,  0.0874,  ..., -0.1004, -0.0853, -0.0592],\n",
       "          [ 0.0439,  0.1465,  0.1408,  ..., -0.1165, -0.0977, -0.0522],\n",
       "          [ 0.0461,  0.1467,  0.1456,  ..., -0.0665, -0.0398, -0.0258],\n",
       "          ...,\n",
       "          [ 0.0441,  0.1496,  0.1170,  ...,  0.0510,  0.0533,  0.0503],\n",
       "          [ 0.0399,  0.1381,  0.1213,  ...,  0.0475,  0.0564,  0.0591],\n",
       "          [ 0.0043,  0.0469,  0.0540,  ..., -0.0008, -0.0015,  0.0179]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0696, -0.0751, -0.0723,  ...,  0.1197,  0.0803,  0.0730],\n",
       "          [ 0.0469,  0.0154,  0.0184,  ...,  0.0353,  0.0607,  0.0976],\n",
       "          [ 0.0418,  0.0165,  0.0188,  ...,  0.0154,  0.0131,  0.0530],\n",
       "          ...,\n",
       "          [ 0.0495, -0.0011, -0.0149,  ...,  0.0444,  0.0353,  0.0265],\n",
       "          [ 0.0551,  0.0102, -0.0041,  ...,  0.0919,  0.0864,  0.0461],\n",
       "          [ 0.1088,  0.0746,  0.0487,  ...,  0.0679,  0.0771,  0.0498]],\n",
       "\n",
       "         [[-0.0653, -0.0325, -0.0354,  ..., -0.0811, -0.1018, -0.0604],\n",
       "          [-0.0603, -0.0663, -0.0625,  ..., -0.0472, -0.0236, -0.0363],\n",
       "          [-0.0601, -0.0638, -0.0616,  ..., -0.0239, -0.0314, -0.0272],\n",
       "          ...,\n",
       "          [-0.0586, -0.0689, -0.0628,  ..., -0.0571, -0.0548, -0.0649],\n",
       "          [-0.0638, -0.0650, -0.0632,  ..., -0.0709, -0.0783, -0.0809],\n",
       "          [-0.0569, -0.0809, -0.0739,  ..., -0.0589, -0.0450, -0.0680]],\n",
       "\n",
       "         [[ 0.0930,  0.0941,  0.0932,  ..., -0.0199,  0.0026,  0.0016],\n",
       "          [ 0.0458,  0.0380,  0.0372,  ...,  0.0428,  0.0281,  0.0338],\n",
       "          [ 0.0491,  0.0415,  0.0362,  ...,  0.0611,  0.0490,  0.0605],\n",
       "          ...,\n",
       "          [ 0.0511,  0.0496,  0.0713,  ...,  0.0371,  0.0474,  0.0609],\n",
       "          [ 0.0442,  0.0352,  0.0673,  ...,  0.0397,  0.0353,  0.0350],\n",
       "          [-0.0107, -0.0109, -0.0123,  ...,  0.0283,  0.0283,  0.0301]]]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h * torch.sigmoid(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "c83f3694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]]], requires_grad=True)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_module(torch.nn.Conv2d(3, 4, 3)).weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "d216fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = train_loop.model.out(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "c9e72688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12fc2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "11821450",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = train_loop.model(x_t, scaled_t, **cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "20ec1343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "be8e06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = train_loop.ddp_model(x_t, scaled_t, **cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "581370a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "101208b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, C = x_t.shape[:2]\n",
    "assert model_output.shape == (B, C * 2, *x_t.shape[2:])\n",
    "model_output, model_var_values = torch.split(model_output, C, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "db956107",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e5e9eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_out = torch.cat([model_output.detach(), model_var_values], dim=1)\n",
    "terms[\"vb\"] = train_loop.diffusion._vb_terms_bpd(\n",
    "    model=lambda *args, r=frozen_out: r,\n",
    "    x_start=batch,\n",
    "    x_t=x_t,\n",
    "    t=t,\n",
    "    clip_denoised=False,\n",
    ")[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7a0d36c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([nan], device='cuda:0', grad_fn=<SWhereBackward>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms['vb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1415000d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "29140934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "37b1d1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "600219f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LossType.MSE: 1>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loop.diffusion.loss_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c1fca6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3d2aac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms[\"mse\"] = mean_flat((target - model_output) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "87ebfd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([nan], device='cuda:0', grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms[\"mse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "770a36c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms[\"loss\"] = terms[\"mse\"] + terms[\"vb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dda4e27a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36mTrainableSpacedDiffusion.training_losses\u001b[0;34m(self, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining_losses\u001b[39m(\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     32\u001b[0m ):  \u001b[38;5;66;03m# pylint: disable=signature-differs\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36mTrainableGaussianDiffusion.training_losses\u001b[0;34m(self, model, x_start, t, model_kwargs, noise)\u001b[0m\n\u001b[1;32m    144\u001b[0m         terms[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvb\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000.0\u001b[39m\n\u001b[1;32m    146\u001b[0m target \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    147\u001b[0m     ModelMeanType\u001b[38;5;241m.\u001b[39mPREVIOUS_X: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_posterior_mean_variance(\n\u001b[1;32m    148\u001b[0m         x_start\u001b[38;5;241m=\u001b[39mx_start, x_t\u001b[38;5;241m=\u001b[39mx_t, t\u001b[38;5;241m=\u001b[39mt\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m     ModelMeanType\u001b[38;5;241m.\u001b[39mEPSILON: noise,\n\u001b[1;32m    152\u001b[0m }[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_mean_type]\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m model_output\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m target\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m x_start\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    154\u001b[0m terms[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m mean_flat((target \u001b[38;5;241m-\u001b[39m model_output) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m terms:\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = compute_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dfe5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop.run_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
